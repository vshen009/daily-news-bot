"""
è‡ªåŠ¨æ›´æ–°é¦–é¡µindex.html

åŠŸèƒ½ï¼š
1. æ‰«æpublic/ç›®å½•ä¸‹çš„æ‰€æœ‰HTMLæ–‡ä»¶
2. è¿‡æ»¤å‡ºè¿‡å»30å¤©çš„æ–°é—»
3. æŒ‰æ—¥æœŸå€’åºæ’åˆ—
4. è‡ªåŠ¨ç”Ÿæˆæ–°é—»å¡ç‰‡åˆ—è¡¨
"""

import os
import re
from datetime import datetime, timedelta
from pathlib import Path
from loguru import logger
import sys

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))
from src.config import Config


class IndexUpdater:
    """é¦–é¡µæ›´æ–°å™¨"""

    def __init__(self, project_root: Path = None):
        if project_root is None:
            project_root = Path(__file__).parent.parent.parent

        self.project_root = project_root
        self.public_dir = project_root / "public"
        self.index_file = project_root / "public" / "index.html"

    def get_news_files(self, days: int = 30) -> list:
        """
        è·å–è¿‡å»Nå¤©çš„æ–°é—»æ–‡ä»¶

        Args:
            days: ä¿ç•™çš„å¤©æ•°ï¼Œé»˜è®¤30å¤©

        Returns:
            list: æ–°é—»æ–‡ä»¶ä¿¡æ¯åˆ—è¡¨ï¼ŒæŒ‰æ—¥æœŸå€’åº
        """
        news_files = []

        # æ£€æŸ¥publicç›®å½•æ˜¯å¦å­˜åœ¨
        if not self.public_dir.exists():
            logger.warning(f"publicç›®å½•ä¸å­˜åœ¨: {self.public_dir}")
            return news_files

        # æ‰«ææ‰€æœ‰HTMLæ–‡ä»¶
        for file_path in self.public_dir.glob("*.html"):
            # æå–æ—¥æœŸï¼ˆæ–‡ä»¶åæ ¼å¼ï¼šYYYY-MM-DD.htmlï¼‰
            match = re.match(r'(\d{4}-\d{2}-\d{2})\.html', file_path.name)
            if not match:
                continue

            date_str = match.group(1)
            try:
                file_date = datetime.strptime(date_str, "%Y-%m-%d")

                # æ£€æŸ¥æ˜¯å¦åœ¨æŒ‡å®šå¤©æ•°å†…ï¼ˆä½¿ç”¨åŒ—äº¬æ—¶é—´ï¼‰
                cutoff_date = Config.get_beijing_time() - timedelta(days=days)
                if file_date >= cutoff_date:
                    # è¯»å–æ ‡é¢˜
                    title = self._extract_title(file_path)

                    # æå–æ–°é—»æ•°é‡
                    article_count = self._extract_article_count(file_path)

                    news_files.append({
                        'date': date_str,
                        'file_date': file_date,
                        'url': file_path.name,  # ç›¸å¯¹äºpublic/index.htmlçš„è·¯å¾„
                        'title': title,
                        'article_count': article_count
                    })

            except ValueError as e:
                logger.warning(f"æ—¥æœŸè§£æå¤±è´¥: {file_path.name}, {e}")
                continue

        # æŒ‰æ—¥æœŸå€’åºæ’åˆ—
        news_files.sort(key=lambda x: x['file_date'], reverse=True)

        return news_files

    def _extract_title(self, file_path: Path) -> str:
        """ä»HTMLæ–‡ä»¶ä¸­æå–æ ‡é¢˜"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

                # å°è¯•æå–<h1>æˆ–<h2>æ ‡ç­¾å†…å®¹
                h1_match = re.search(r'<h1[^>]*>(.*?)</h1>', content, re.DOTALL)
                if h1_match:
                    title = h1_match.group(1).strip()
                    # ç§»é™¤HTMLæ ‡ç­¾
                    title = re.sub(r'<[^>]+>', '', title)
                    if len(title) > 10:
                        return title[:100]  # é™åˆ¶é•¿åº¦

                # æå–<title>æ ‡ç­¾
                title_match = re.search(r'<title>(.*?)</title>', content)
                if title_match:
                    title = title_match.group(1).strip()
                    if len(title) > 10:
                        return title[:100]

        except Exception as e:
            logger.warning(f"è¯»å–æ ‡é¢˜å¤±è´¥: {file_path.name}, {e}")

        # é»˜è®¤æ ‡é¢˜
        return f"è´¢ç»æ—¥æŠ¥ - {file_path.stem}"

    def _extract_article_count(self, file_path: Path) -> int:
        """ä»HTMLæ–‡ä»¶ä¸­æå–æ–°é—»æ•°é‡"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

                # ç»Ÿè®¡ <article class="news-card ..."> çš„æ•°é‡
                article_count = len(re.findall(r'<article[^>]*class="[^"]*news-card', content))

                if article_count > 0:
                    return article_count

        except Exception as e:
            logger.warning(f"è¯»å–æ–°é—»æ•°é‡å¤±è´¥: {file_path.name}, {e}")

        # å¦‚æœæ— æ³•æå–ï¼Œè¿”å›0
        return 0

    def update_index(self, days: int = 30) -> bool:
        """
        æ›´æ–°index.html

        Args:
            days: ä¿ç•™çš„å¤©æ•°ï¼Œé»˜è®¤30å¤©

        Returns:
            bool: æ˜¯å¦æˆåŠŸæ›´æ–°
        """
        try:
            logger.info(f"å¼€å§‹æ›´æ–°é¦–é¡µï¼ˆä¿ç•™è¿‡å»{days}å¤©ï¼‰")

            # è·å–æ–°é—»æ–‡ä»¶åˆ—è¡¨
            news_files = self.get_news_files(days)

            if not news_files:
                logger.warning("æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ–°é—»æ–‡ä»¶")
                return False

            logger.info(f"æ‰¾åˆ°{len(news_files)}ä¸ªæ–°é—»æ–‡ä»¶")

            # ç”ŸæˆJavaScriptæ•°ç»„
            news_list_js = self._generate_news_list_js(news_files)

            # è¯»å–index.htmlæ¨¡æ¿ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºé»˜è®¤æ¨¡æ¿
            if not self.index_file.exists():
                logger.warning(f"index.htmlä¸å­˜åœ¨ï¼Œåˆ›å»ºé»˜è®¤æ¨¡æ¿: {self.index_file}")
                self._create_default_index(news_files)
                return True

            with open(self.index_file, 'r', encoding='utf-8') as f:
                content = f.read()

            # æ›¿æ¢newsListæ•°ç»„
            pattern = r'const newsList = \[.*?\];'
            replacement = f'const newsList = [\n{news_list_js}\n        ];'

            new_content = re.sub(pattern, replacement, content, flags=re.DOTALL)

            # å†™å›æ–‡ä»¶
            with open(self.index_file, 'w', encoding='utf-8') as f:
                f.write(new_content)

            logger.info(f"âœ“ é¦–é¡µæ›´æ–°æˆåŠŸï¼ŒåŒ…å«{len(news_files)}å¤©æ–°é—»")
            return True

        except Exception as e:
            logger.error(f"æ›´æ–°é¦–é¡µå¤±è´¥: {e}")
            return False

    def _generate_news_list_js(self, news_files: list) -> str:
        """ç”ŸæˆJavaScriptæ•°ç»„çš„å­—ç¬¦ä¸²"""
        lines = []

        for news in news_files:
            date = news['date']
            url = news['url']
            title = news['title'].replace("'", "\\'").replace('"', '\\"')
            article_count = news.get('article_count', 0)

            lines.append(f"            {{")
            lines.append(f"                date: '{date}',")
            lines.append(f"                url: '{url}',")
            lines.append(f"                title: '{title}',")
            lines.append(f"                articleCount: {article_count}")
            lines.append(f"            }},")

        # ç§»é™¤æœ€åä¸€ä¸ªé€—å·
        if lines:
            lines[-1] = lines[-1].rstrip(',')

        return '\n'.join(lines)

    def _create_default_index(self, news_files: list = None):
        """
        åˆ›å»ºé»˜è®¤çš„ index.html

        Args:
            news_files: æ–°é—»æ–‡ä»¶åˆ—è¡¨ï¼ˆå¦‚æœä¸ºNoneï¼Œåˆ™åˆ›å»ºç©ºæ¨¡æ¿ï¼‰
        """
        if news_files is None:
            news_files = []

        # ç”Ÿæˆ JavaScript æ•°ç»„
        news_list_js = self._generate_news_list_js(news_files)

        # é»˜è®¤ index.html æ¨¡æ¿
        template = '''<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>è´¢ç»æ—¥æŠ¥ - æ¯æ—¥é‡‘èæ–°é—»æ±‡æ€»</title>
    <meta name="description" content="æ¯æ—¥ç²¾é€‰è´¢ç»æ–°é—»ï¼Œæ¶µç›–å›½å†…ã€äºšå¤ªã€ç¾å›½æ¬§æ´²å¸‚åœºåŠ¨æ€">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@400;500;700&family=Inter:wght@400;500;600&display=swap" rel="stylesheet">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Noto Sans SC', 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);
            min-height: 100vh;
            color: #eaeaea;
            padding: 20px;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
        }

        header {
            text-align: center;
            padding: 60px 20px 40px;
        }

        h1 {
            font-size: 2.5rem;
            font-weight: 700;
            background: linear-gradient(135deg, #ff6b6b 0%, #feca57 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            margin-bottom: 10px;
        }

        .subtitle {
            font-size: 1.1rem;
            color: #a0a0a0;
        }

        .news-grid {
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(320px, 1fr));
            gap: 24px;
            padding: 40px 20px;
        }

        .news-card {
            background: rgba(255, 255, 255, 0.05);
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.1);
            border-radius: 16px;
            padding: 24px;
            transition: all 0.3s ease;
            cursor: pointer;
        }

        .news-card:hover {
            transform: translateY(-4px);
            box-shadow: 0 12px 40px rgba(255, 107, 107, 0.15);
            border-color: rgba(255, 107, 107, 0.3);
        }

        .news-date {
            font-size: 0.9rem;
            color: #ff6b6b;
            font-weight: 600;
            margin-bottom: 8px;
        }

        .news-title {
            font-size: 1.1rem;
            font-weight: 500;
            color: #ffffff;
            margin-bottom: 12px;
            line-height: 1.5;
        }

        .news-meta {
            font-size: 0.85rem;
            color: #a0a0a0;
        }

        .empty-state {
            text-align: center;
            padding: 80px 20px;
            color: #a0a0a0;
        }

        .empty-state h2 {
            font-size: 1.8rem;
            margin-bottom: 16px;
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 2rem;
            }

            .news-grid {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>ğŸ“ˆ è´¢ç»æ—¥æŠ¥</h1>
            <p class="subtitle">æ¯æ—¥ç²¾é€‰é‡‘èæ–°é—»æ±‡æ€»</p>
        </header>

        <main id="news-container" class="news-grid"></main>
    </div>

    <script>
        const newsList = [
        ];

        function renderNews() {
            const container = document.getElementById('news-container');

            if (newsList.length === 0) {
                container.innerHTML = `
                    <div class="empty-state">
                        <h2>æš‚æ— æ–°é—»</h2>
                        <p>æ•¬è¯·æœŸå¾…...</p>
                    </div>
                `;
                return;
            }

            container.innerHTML = newsList.map(news => `
                <article class="news-card" onclick="window.location.href='${news.url}'">
                    <div class="news-date">${news.date}</div>
                    <h2 class="news-title">${news.title}</h2>
                    <div class="news-meta">ğŸ“° ${news.articleCount} æ¡æ–°é—»</div>
                </article>
            `).join('');
        }

        // é¡µé¢åŠ è½½æ—¶æ¸²æŸ“æ–°é—»
        document.addEventListener('DOMContentLoaded', renderNews);
    </script>
</body>
</html>'''

        # æ›¿æ¢ newsList
        if news_files:
            pattern = r'const newsList = \[.*?\];'
            replacement = f'const newsList = [\n{news_list_js}\n        ];'
            template = re.sub(pattern, replacement, template, flags=re.DOTALL)

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.index_file.parent.mkdir(parents=True, exist_ok=True)

        # å†™å…¥æ–‡ä»¶
        with open(self.index_file, 'w', encoding='utf-8') as f:
            f.write(template)

        logger.info(f"âœ“ å·²åˆ›å»ºé»˜è®¤ index.htmlï¼ŒåŒ…å« {len(news_files)} å¤©æ–°é—»")


def update_index_html(days: int = 30) -> bool:
    """
    æ›´æ–°index.htmlçš„ä¾¿æ·å‡½æ•°

    Args:
        days: ä¿ç•™çš„å¤©æ•°ï¼Œé»˜è®¤30å¤©

    Returns:
        bool: æ˜¯å¦æˆåŠŸæ›´æ–°
    """
    updater = IndexUpdater()
    return updater.update_index(days)


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    import sys
    from loguru import logger

    logger.remove()
    logger.add(sys.stderr, format="<green>{time:HH:mm:ss}</green> | <level>{level: <8}</level> | <level>{message}</level>")

    # æ›´æ–°é¦–é¡µï¼Œä¿ç•™30å¤©
    success = update_index_html(days=30)

    if success:
        logger.info("âœ… é¦–é¡µæ›´æ–°å®Œæˆ")
    else:
        logger.error("âŒ é¦–é¡µæ›´æ–°å¤±è´¥")
        sys.exit(1)
